{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a29909e9-d3fe-44f0-8908-6384c0ba27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f756b1a0-ec1b-47eb-bebf-e2199308133c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb7b191f-0c3e-4571-9501-4fbd2662807f",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = \"\"\"\n",
    "Natural Language Processing (NLP) is a sub-field of artificial intelligence (AI) that deals with the interaction \n",
    "between computers and human (natural) languages. The ultimate goal of NLP is to enable computers to read, \n",
    "understand, and derive meaning from human languages in a manner that is both valuable and useful.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9968615-5272-4468-8d50-fae7207cfcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8619e6e7-6748-4011-b583-724a15b1eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bf41388-4686-48a3-aa54-c8c26cea1081",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bf933e7-788d-4075-a273-f9264aa5e008",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5f488f26-d0bc-40af-9332-c806322532d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'sub-field', 'of', 'artificial', 'intelligence', '(', 'AI', ')', 'that', 'deals', 'with', 'the', 'interaction', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages.', 'The', 'ultimate', 'goal', 'of', 'NLP', 'is', 'to', 'enable', 'computers', 'to', 'read', ',', 'understand', ',', 'and', 'derive', 'meaning', 'from', 'human', 'languages', 'in', 'a', 'manner', 'that', 'is', 'both', 'valuable', 'and', 'useful', '.']\n",
      "\n",
      "Filtered Tokens (Stopwords Removed): ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'sub-field', 'artificial', 'intelligence', '(', 'AI', ')', 'deals', 'interaction', 'computers', 'human', '(', 'natural', ')', 'languages.', 'ultimate', 'goal', 'NLP', 'enable', 'computers', 'read', ',', 'understand', ',', 'derive', 'meaning', 'human', 'languages', 'manner', 'valuable', 'useful', '.']\n",
      "\n",
      "Stemmed Tokens: ['natur', 'languag', 'process', '(', 'nlp', ')', 'sub-field', 'artifici', 'intellig', '(', 'ai', ')', 'deal', 'interact', 'comput', 'human', '(', 'natur', ')', 'languages.', 'ultim', 'goal', 'nlp', 'enabl', 'comput', 'read', ',', 'understand', ',', 'deriv', 'mean', 'human', 'languag', 'manner', 'valuabl', 'use', '.']\n",
      "\n",
      "Lemmatized Tokens: ['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'sub-field', 'artificial', 'intelligence', '(', 'AI', ')', 'deal', 'interaction', 'computer', 'human', '(', 'natural', ')', 'languages.', 'ultimate', 'goal', 'NLP', 'enable', 'computer', 'read', ',', 'understand', ',', 'derive', 'meaning', 'human', 'language', 'manner', 'valuable', 'useful', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens:\", tokens)\n",
    "print(\"\\nFiltered Tokens (Stopwords Removed):\", filtered_tokens)\n",
    "print(\"\\nStemmed Tokens:\", stemmed_tokens)\n",
    "print(\"\\nLemmatized Tokens:\", lemmatized_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01df3e5a-ab0e-4ee6-b03b-e7e61cd0d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66c68818-83a7-47d6-94fa-c48a4d2bc12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Representation:\n",
      "        and  artificial   between  computers     deals    enable     field  \\\n",
      "0  0.000000    0.351711  0.000000   0.000000  0.000000  0.000000  0.351711   \n",
      "1  0.274746    0.000000  0.361258   0.274746  0.361258  0.000000  0.000000   \n",
      "2  0.215996    0.000000  0.000000   0.215996  0.000000  0.284008  0.000000   \n",
      "\n",
      "       goal     human  intelligence  ...   natural       nlp        of  \\\n",
      "0  0.000000  0.000000      0.351711  ...  0.351711  0.207726  0.267485   \n",
      "1  0.000000  0.274746      0.000000  ...  0.000000  0.213365  0.000000   \n",
      "2  0.284008  0.215996      0.000000  ...  0.000000  0.167740  0.215996   \n",
      "\n",
      "    process  processing       sub       the        to  understand      with  \n",
      "0  0.000000    0.351711  0.351711  0.000000  0.000000    0.000000  0.000000  \n",
      "1  0.000000    0.000000  0.000000  0.274746  0.000000    0.000000  0.361258  \n",
      "2  0.284008    0.000000  0.000000  0.215996  0.568016    0.284008  0.000000  \n",
      "\n",
      "[3 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Sample Document Corpus (Multiple Documents)\n",
    "documents = [\n",
    "    \"Natural Language Processing (NLP) is a sub-field of artificial intelligence.\",\n",
    "    \"NLP deals with the interaction between computers and human languages.\",\n",
    "    \"The goal of NLP is to enable computers to understand and process human language.\"\n",
    "]\n",
    "\n",
    "# Calculate TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get Feature Names (Words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display the TF-IDF values\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "print(\"\\nTF-IDF Representation:\")\n",
    "print(df_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abe6992-e2a1-456e-8700-6a9848754444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
